# 连接 ELasticsearch 的 client 节点
elasticsearchHosts: "http://elasticsearch-client:9200"

# # 指定镜像及tag
# image: "docker.elastic.co/logstash/logstash"
# imageTag: "7.15.0"

# Pod 部署在 node2 节点上
nodeSelector:
  usefulness: elastic
  
# 资源
resources:
  requests:
    cpu: "250m"
    memory: "1Gi"
  limits:
    cpu: "500m"
    memory: "1Gi"
    
persistence:
  enabled: true
    
logstashPipeline:
  logstash.conf: |
    input {
      kafka {
        bootstrap_servers => "kafka-0.kafka-headless.elastic.svc.cluster.local:9092,kafka-1.kafka-headless.elastic.svc.cluster.local:9092,kafka-2.kafka-headless.elastic.svc.cluster.local:9092"
        client_id => "${LOGSTASH_ID}"
        topics => ["filebeat"]
        group_id => "logstash"
        decorate_events => true
        codec => "json"
      }
    }

    output {
      elasticsearch {
        hosts => ["http://elasticsearch-client:9200"]
        index => "filebeat-kafka-%{[kubernetes][namespace]}-%{[kubernetes][pod][name]}-%{+YYYY.MM.dd}"
        user => "${XPACK_MONITORING_ELASTICSEARCH_USERNAME}"
        password => "${XPACK_MONITORING_ELASTICSEARCH_PASSWORD}"
      }
    }    

# 以环境变量的方式写入账号密码
extraEnvs:
  - name: XPACK_MONITORING_ELASTICSEARCH_HOSTS
    value: '"http://elasticsearch-client:9200"'
  - name: XPACK_MONITORING_ELASTICSEARCH_USERNAME
    valueFrom:
      secretKeyRef:
        name: elastic-credentials
        key: username
  - name: XPACK_MONITORING_ELASTICSEARCH_PASSWORD
    valueFrom:
      secretKeyRef:
        name: elastic-credentials
        key: password
  - name: LOGSTASH_ID
    valueFrom:
      fieldRef:
        fieldPath: metadata.name

livenessProbe: null

readinessProbe:
  httpGet: null
  exec:
    command:
      - curl
      - localhost:9600